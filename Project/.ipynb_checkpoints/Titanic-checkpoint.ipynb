{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data acquisition\n",
    "Download the data from this link : https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('data/titanic/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data description\n",
    "Try to get the main information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Exploratory data analysis\n",
    "For every data science project, the most important part is understanding the data.\n",
    "Exploratory data anaylysis is an analysis approach that identifies general patterns in the data. Try to learn as much as you can about the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Separate the dataset to 2 dataset : one for numerical data and one for categorical data\n",
    "df_num = ...\n",
    "df_cat = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Using matplotlib histograms, draw the distributions for numerical data\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Using seaborn, draw the heatmap for the correlation matrix and explain its role\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : \n",
    "    # Look up pivot tables in pandas and explain what they do\n",
    "    # draw them for the numerical variables with a mean aggrregation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Using sns barplot, draw the barplots for the categorical variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : \n",
    "    # Create the pivot table for the categorical variables for which it makes sense\n",
    "    # Explain why it doesn not make sense for the others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : \n",
    "    # Explore the variable Cabin's values\n",
    "    # Can we use this variable directly? if not, how can we exploit it efficiently\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Data Engineering\n",
    "When exploiting datasets, data engineering is an important preprocessing step. Its goal is to extract more information from the data so to increase the predictive power of the machine learning model.\n",
    "Identify some variables on which we can apply data engineering and explain what type of information can be extratced from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example of data engineering from the variable Cabin, we used it to create a new variable called Cabin_multiple that contains the number of cabins per passenger.\n",
    "df_train['Cabin_multiple'] = df_train.Cabin.apply(lambda x : 0 if pd.isna(x) else len(x.split(' ')))\n",
    "df_train['Cabin_multiple'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Create the pivot table for the newly created attribute.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Create the variables you think might be interesting then draw the pivot tables for the variables you create\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Data Preperation\n",
    "All of the operations done so far were done on the training set. However, when we test our model, the test data needs to have the same format as the training data (the created variables, the deleted variables, ...).\n",
    "\n",
    "### 5.1) Data transformation:\n",
    "A quick way to do that, is to combine both datasets and apply the operations applied previously on the combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/titanic/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_train['train'] = 1\n",
    "df_test['train'] = 0\n",
    "df_test['Survived'] = np.NaN\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Use the .info() function from pandas and get the information about the dataset after the changes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['Age'] = df_all['Age'].fillna(df_all['Age'].median())\n",
    "df_all['Fare'] = df_all['Fare'].fillna(df_all['Fare'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2) Handling missing data : \n",
    "There are different ways to handle missing data in a dataset. Name some of them.\n",
    "\n",
    "List the variables with missing values.\n",
    "\n",
    "For every variable named, handle the missing variables in the way you see fits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3) Categorical variables transformation : \n",
    "Fully connected neural networks (FCNNs) are known for not being able to handle categorical variables in their natural state.\n",
    "\n",
    "Using one hot encoding (.get dummies function from pandas), create a new version of the dataset with transformed categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we transoform the Pclass variable to string because it is a categorical variable\n",
    "df_all['Pclass'] = df_all['Pclass'].astype(str)\n",
    "\n",
    "# TO-DO : One hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Get the information for the newly created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Create a second version of the dataset from the one previously created but without the variables you created with data engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Separate the training data from the test data\n",
    "\n",
    "X_train = \n",
    "X_test = \n",
    "Y_train = \n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO : Separate the training data from the test data for the dataset without variables that are feature engineered\n",
    "\n",
    "X_train_bis = \n",
    "X_test_bis = \n",
    "print(X_train_bis.shape, Y_train.shape)\n",
    "print(X_test_bis.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Model Creation\n",
    "Using keras, create a Neural Network and train it on the data generated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# TO-DO : Model creation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TO-DO : Model training \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code transforms the results to binary (0 or 1) from the probabilities predicted by the model\n",
    "pred_val = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
    "len(pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code formats the results to a submission format (Call the lab assistant to learn more about this !)\n",
    "formated_results = {'PassengerId' : df_test['PassengerId'], 'Survived' : pred_val}\n",
    "formated_results = pd.DataFrame(formated_results)\n",
    "formated_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results in a csv file\n",
    "formated_results.to_csv('data/titanic/results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
